{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook creates a plot of each feature and calculates the pearson and spearman correlation. \n",
    "#also does some preliminary statistical tests\n",
    "import matplotlib.pyplot as plt\n",
    "#import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "from scipy.stats import pearsonr\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#path = \"D:/MASTERS/IMPACT_DATA.csv\"\n",
    "path = 'D:/MASTERS/IMPACT_DATA_COMBINED_SWAP.csv'\n",
    "#path = 'D:/MASTERS/IMPACT_DATA_2020_2.csv'\n",
    "save_path = \"D:/MASTERS/VISUALISATIONS/2020/\"\n",
    "#save_path = \"D:/MASTERS/VISUALISATIONS/COMBINED/\"\n",
    "path_1 = 'D:/MASTERS/IMPACT_DATA.csv'\n",
    "path_2 = 'D:/MASTERS/IMPACT_DATA_2020_2.csv'\n",
    "\n",
    "#WHEN CHANGING DATA, DOUBLE CHACK FILE NAMES FOR SAVING, TO AVOID OVERWRITING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "impact_df = pd.read_csv(path) # COMBINED DATASET\n",
    "impact_df1 = pd.read_csv(path_1) #for 2 plots on same graph 2024\n",
    "impact_df2 = pd.read_csv(path_2) #for 2 plots on same graph 2020\n",
    "\n",
    "#array with units to each plotted variable, listed in order of cols in impact_df\n",
    "units = [' ', ' ','(/s)','(krad/s^2)','(g)','(rad/s)','(krad/s^2)','(krad/s^2)','(krad/s^2)','(rad/s)','(rad/s)','(rad/s)','(g)','(g)','(g)']\n",
    "\n",
    "headers = impact_df.columns\n",
    "ys = np.array(headers[1:3]) #dependent/output variables (strain)\n",
    "xs = np.array(headers[3:15]) #independent/input variables/features (kinematics)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "colours = ['#C90062','#029E6D'] #cherry, turquoise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot data & save\n",
    "#2 nested for loops\n",
    "\n",
    "for k in range(len(ys)):\n",
    "    #run through strain and strain rate\n",
    "    \n",
    "    for n in range(len(xs)):\n",
    "        #run through plots for each feature-input pairing.\n",
    "        x = impact_df2[xs[n]] #x is kinamatics, 12 cols\n",
    "        y = impact_df2[ys[k]] #y is inputs stain and strainrate cols.\n",
    "        plt.scatter(x, y, color=colours[k]) #0 or 1 of colour dots\n",
    "        plt.xlabel(xs[n] + ' ' + units[n+3]) #3-14 (inclusive) of unit array\n",
    "        plt.ylabel(ys[k] + ' ' + units[k]) #0 and 1 of unit array\n",
    "        time.sleep(0.2)\n",
    "        plt.savefig(save_path + ys[k] +'_'+ xs[n]+'.png', dpi=300)\n",
    "        print(xs[n]+' '+ ys[k] + ' saved')\n",
    "        plt.close()\n",
    "\n",
    "print('All files completed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot data & save 2 datasets with same plots on the same plot.\n",
    "#2 nested for loops\n",
    "\n",
    "for k in range(len(ys)):\n",
    "    #run through strain and strain rate\n",
    "    \n",
    "    for n in range(len(xs)):\n",
    "        #run through plots for each feature-input pairing.\n",
    "        x1 = impact_df1[xs[n]] #x is kinamatics, 12 cols\n",
    "        y1 = impact_df1[ys[k]] #y is inputs stain and strainrate cols.\n",
    "        x2 = impact_df2[xs[n]]\n",
    "        y2 = impact_df2[ys[k]]\n",
    "\n",
    "        plt.scatter(x1, y1, color=colours[k],alpha=0.7) #0 or 1 of colour dots\n",
    "        plt.scatter(x2, y2, marker='x', color=colours[k],alpha=0.7) #0 or 1 of colour dots\n",
    "        plt.xlabel(xs[n] + ' ' + units[n+3]) #3-14 (inclusive) of unit array\n",
    "        plt.ylabel(ys[k] + ' ' + units[k]) #0 and 1 of unit array\n",
    "        time.sleep(0.2)\n",
    "        plt.savefig(save_path +'_dataset_partition_'+ ys[k] +'_'+ xs[n]+'.png', dpi=300)\n",
    "        print(xs[n]+' '+ ys[k] + ' saved')\n",
    "        plt.close()\n",
    "\n",
    "print('All files completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Pearsons correlation \n",
    "correlation_results = {}\n",
    "correlation_results['X'] = []\n",
    "correlation_results['Y'] = []\n",
    "correlation_results['Coefficient'] = []\n",
    "correlation_results['p-value'] = []\n",
    "#run through all combos\n",
    "\n",
    "for i in range(len(ys)):\n",
    "    #run through strain and strain rate\n",
    "    \n",
    "    for j in range(len(xs)):\n",
    "        #run through plots for each feature-input pairing.\n",
    "        x = impact_df[xs[j]] #x is kinamatics, 12 cols\n",
    "        y = impact_df[ys[i]] #y is inputs stain and strainrate cols.\n",
    "        print(x)\n",
    "        print(y)\n",
    "        time.sleep(0.1)\n",
    "        #calculate pearsons rank\n",
    "        corr, p_value = pearsonr(x,y)\n",
    "        #append the dictionary\n",
    "        correlation_results['X'].append(xs[j])\n",
    "        correlation_results['Y'].append(ys[i])\n",
    "        correlation_results['Coefficient'].append(corr)\n",
    "        correlation_results['p-value'].append(p_value)\n",
    "        print('pearsons calculated for: ' + xs[j] + ' ' + ys[i] )\n",
    "\n",
    "print('calculations complete for all pairs')\n",
    "\n",
    "#save as a csv\n",
    "#creating a csv with all columns\n",
    "df = pd.DataFrame(correlation_results)\n",
    "#df.to_csv('D:/MASTERS/correlation_results_pearsons_2024.csv', index=False)\n",
    "#df.to_csv('D:/MASTERS/correlation_results_pearsons_2020.csv', index=False)\n",
    "df.to_csv('D:/MASTERS/correlation_results_pearsons_COMBINED.csv', index=False)\n",
    "print('csv saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a seaborn heatmap for correlation to check for multicollinearity FOR SIMULATED HELMET TEST IMPACTS\n",
    "data = impact_df\n",
    "#num_features = data.drop(columns=['Impact label','Type','Strain 90th%','Strain rate 90th%','peak rot acc resultant','peak lin acc resultant','peak rot vel resultant'])\n",
    "num_features = data.drop(columns=['Impact label','Type','Strain 90th%','Strain rate 90th%'])\n",
    "sns.heatmap(num_features.corr())\n",
    "#pd.DataFrame(num_features.corr()).to_csv(\"D:/MASTERS/heatmap_all_2024.csv\")\n",
    "#pd.DataFrame(num_features.corr()).to_csv(\"D:/MASTERS/heatmap_all_2020.csv\")\n",
    "#pd.DataFrame(num_features.corr()).to_csv(\"D:/MASTERS/heatmap_all_COMBINED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strains_object = [nYR_strain,pXR_strain,pYR_strain,pZR_strain]\n",
    "#print(strains_object)\n",
    "print(nYR_strainrate)\n",
    "print(pYR_strainrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising k vs mean squared error for k-nearest neighbours algorithm\n",
    "y = [0.066889537,\n",
    "0.065151135,\n",
    "0.068091236,\n",
    "0.068143261,\n",
    "0.066059557,\n",
    "0.06357581,\n",
    "0.064536553,\n",
    "0.064143463,\n",
    "0.063101534,\n",
    "]\n",
    "x = [2,3,4,5,6,7,8,9,10]\n",
    "z = [0.580613344,\n",
    "0.602705831,\n",
    "0.564184754,\n",
    "0.566048596,\n",
    "0.593090399,\n",
    "0.620299321,\n",
    "0.608996983,\n",
    "0.611480531,\n",
    "0.62368948,\n",
    "\n",
    "]\n",
    "plt.scatter(x, y, color=colours[0])\n",
    "#plt.scatter(x, z, color=colours[1])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mann u whitney test results for 2020 and 2024 datasets\n",
      "strain p value: 2.79530221414727e-06\n",
      "strainrate p value: 0.036417681270433225\n"
     ]
    }
   ],
   "source": [
    "#import datasets\n",
    "#MANN WHITNEY U TEST\n",
    "path_2020 = 'D:/MASTERS/IMPACT_DATA_2020_2.csv'\n",
    "path_2024 = 'D:/MASTERS/IMPACT_DATA.csv'\n",
    "\n",
    "df_2020 = pd.read_csv(path_2020) \n",
    "df_2024 = pd.read_csv(path_2024)\n",
    "\n",
    "strain_2020 = df_2020['Strain 90th%']\n",
    "strain_rate_2020 = df_2020['Strain rate 90th%']\n",
    "strain_2024 = df_2024['Strain 90th%']\n",
    "strain_rate_2024 = df_2024['Strain rate 90th%']\n",
    "#print(strain_2020)\n",
    "\n",
    "#mann u whitney test to see if the two datasets are from the same distribution\n",
    "U1_strain, p_value_strain = mannwhitneyu(strain_2024, strain_2020, method=\"exact\")\n",
    "U1_strainerate, p_value_strainrate = mannwhitneyu(strain_rate_2024, strain_rate_2020, method=\"exact\")\n",
    "\n",
    "print('mann u whitney test results for 2020 and 2024 datasets')\n",
    "print('strain p value:',p_value_strain)\n",
    "print('strainrate p value:',p_value_strainrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal wallace test 2020 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.085729, 0.095442, 0.065074, 0.059856, 0.016012, 0.057699, 0.124541, 0.047856, 0.052251, 0.188931, 0.093291, 0.096036, 0.061356, 0.106178, 0.08441, 0.053691, 0.079859, 0.10858, 0.100743, 0.05524, 0.059864, 0.08616, 0.084635, 0.152337, 0.077059, 0.038228, 0.080627] [0.11107, 0.087186, 0.070576, 0.048034, 0.014238, 0.071586, 0.146096, 0.050931, 0.056933, 0.077835, 0.100894, 0.083116, 0.035822, 0.090281, 0.0928, 0.067367, 0.118959, 0.111607, 0.057628, 0.06486, 0.035445, 0.110232, 0.084774, 0.13831, 0.089354, 0.058145, 0.100018] [0.109917, 0.119072, 0.060024, 0.105992, 0.014602, 0.081327, 0.12001, 0.063641, 0.068964, 0.108576, 0.087754, 0.063822, 0.052083, 0.0823, 0.079374, 0.063579, 0.087961, 0.093274, 0.061925, 0.080489, 0.079309, 0.093932, 0.083394, 0.129845, 0.119804, 0.101747, 0.104289]\n",
      "results strain 2020:  KruskalResult(statistic=1.1620328548964096, pvalue=0.5593295596218858)\n",
      "results strain rate 2020:  KruskalResult(statistic=6.397403727123702, pvalue=0.040815153240897684)\n",
      "posthoc results strain 2020:\n",
      "          1    2         3\n",
      "1  1.000000  1.0  0.934274\n",
      "2  1.000000  1.0  1.000000\n",
      "3  0.934274  1.0  1.000000\n",
      "posthoc results strainrates 2020:\n",
      "          1         2         3\n",
      "1  1.000000  0.538849  0.034444\n",
      "2  0.538849  1.000000  0.707147\n",
      "3  0.034444  0.707147  1.000000\n"
     ]
    }
   ],
   "source": [
    "#Kruskal-wallace test and post hoc dunn test, see if type of impact is significant for 2020 data\n",
    "#split dataset by impact type:\n",
    "#for all datapoints\n",
    "\n",
    "X_strain = []\n",
    "Y_strain = []\n",
    "Z_strain = []\n",
    "\n",
    "X_strainrate = []\n",
    "Y_strainrate = []\n",
    "Z_strainrate = []\n",
    "\n",
    "types = df_2020['Type']\n",
    "strains = df_2020['Strain rate 90th%']\n",
    "strainrates = df_2020['Strain 90th%'] \n",
    "\n",
    "\n",
    "for a in range(len(df_2020)):\n",
    "    if types[a] == 'X':\n",
    "        #append to X-ROT strain and strainrate\n",
    "        X_strain.append(strains[a])\n",
    "        X_strainrate.append(strainrates[a])\n",
    "        #print('impact',a, 'is z-rot')\n",
    "    elif types[a] == 'Y':\n",
    "        #append to Y-ROT strain and strainrate\n",
    "        Y_strain.append(strains[a])\n",
    "        Y_strainrate.append(strainrates[a])\n",
    "        #print('impact',a, 'is y-rot')\n",
    "    elif types[a] == 'Z':\n",
    "        #append to Z-ROT strain and strainrate\n",
    "        Z_strain.append(strains[a])\n",
    "        Z_strainrate.append(strainrates[a])\n",
    "        #print('impact',a, 'is Z-rot')\n",
    "\n",
    "print(X_strain, Y_strain, Z_strain)\n",
    "\n",
    "\n",
    "result_strain = kruskal(X_strain, Y_strain, Z_strain)\n",
    "result_strainrate = kruskal(X_strainrate, Y_strainrate, Z_strainrate)\n",
    "print('results strain 2020: ',result_strain)\n",
    "print('results strain rate 2020: ', result_strainrate)\n",
    "\n",
    "posthoc_results_strains = posthoc_dunn([X_strain, Y_strain, Z_strain], p_adjust='bonferroni')\n",
    "posthoc_results_strainrates = posthoc_dunn([X_strainrate, Y_strainrate, Z_strainrate], p_adjust='bonferroni')\n",
    "print('posthoc results strain 2020:')\n",
    "print(posthoc_results_strains)\n",
    "print('posthoc results strainrates 2020:')\n",
    "print(posthoc_results_strainrates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal wallace test for 2024 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.094569, 0.056699, 0.045995, 0.057064, 0.065047, 0.043656, 0.116031, 0.066257, 0.019117, 0.11321, 0.038514, 0.095377, 0.053273, 0.047835, 0.052042, 0.030587, 0.08962, 0.078049, 0.087255, 0.060979, 0.072502, 0.087429, 0.06964, 0.068529, 0.05689, 0.071814, 0.036588, 0.026494, 0.074005] [0.117818, 0.107863, 0.10084, 0.088068, 0.079324, 0.088811, 0.106767, 0.133327, 0.049746, 0.106401, 0.060468, 0.092454, 0.086379, 0.051567, 0.085689, 0.058695, 0.13439, 0.065642, 0.067046, 0.120929, 0.040643, 0.082632, 0.068125, 0.114101, 0.057611, 0.084384, 0.050435, 0.040148, 0.110629] [0.095109, 0.063528, 0.044781, 0.033572, 0.056134, 0.060636, 0.07477, 0.061753, 0.040431, 0.067855, 0.05773, 0.052594, 0.042754, 0.028825, 0.046313, 0.037779, 0.046961, 0.038236, 0.061726, 0.070265, 0.041813, 0.063239, 0.040707, 0.052369, 0.042946, 0.069041, 0.046018, 0.033473, 0.05079] [0.170879, 0.083381, 0.173335, 0.11566, 0.107991, 0.099292, 0.06981, 0.052804, 0.169047, 0.109835, 0.181637, 0.089085, 0.062774, 0.118941, 0.07555, 0.118354, 0.086901, 0.067748, 0.179869, 0.050705, 0.107764, 0.085746, 0.088697, 0.181351, 0.088823, 0.058913]\n",
      "KruskalResult(statistic=38.19949371092105, pvalue=2.5645264141112645e-08)\n",
      "KruskalResult(statistic=45.74024578123323, pvalue=6.440543340034697e-10)\n",
      "          1             2         3             4\n",
      "1  1.000000  3.324690e-01  0.124538  6.957705e-04\n",
      "2  0.332469  1.000000e+00  0.000141  6.498837e-08\n",
      "3  0.124538  1.414516e-04  1.000000  6.495502e-01\n",
      "4  0.000696  6.498837e-08  0.649550  1.000000e+00\n",
      "          1             2         3             4\n",
      "1  1.000000  7.283640e-04  1.000000  2.913285e-02\n",
      "2  0.000728  1.000000e+00  0.000021  3.372780e-10\n",
      "3  1.000000  2.123070e-05  1.000000  2.451839e-01\n",
      "4  0.029133  3.372780e-10  0.245184  1.000000e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Kruskal-wallace test and post hoc dunn test, see if type of impact is significant.2020 data\n",
    "#split dataset by impact type:\n",
    "#for all datapoints\n",
    "nYR_strain = []\n",
    "pXR_strain = []\n",
    "pYR_strain = []\n",
    "pZR_strain = []\n",
    "\n",
    "nYR_strainrate = []\n",
    "pXR_strainrate = []\n",
    "pYR_strainrate = []\n",
    "pZR_strainrate = []\n",
    "\n",
    "types = df_2024['Type']\n",
    "strains = df_2024['Strain rate 90th%']\n",
    "strainrates = df_2024['Strain 90th%'] \n",
    "\n",
    "\n",
    "for a in range(len(df_2024)):\n",
    "    if types[a] == 'nYR':\n",
    "        #append to nyrstrain and strainrate\n",
    "        nYR_strain.append(strains[a])\n",
    "        nYR_strainrate.append(strainrates[a])\n",
    "        #print('impact',a, 'is nYR')\n",
    "    elif types[a] == 'pXR':\n",
    "        #append to pxr strain and strainrate\n",
    "        pXR_strain.append(strains[a])\n",
    "        pXR_strainrate.append(strainrates[a])\n",
    "        #print('impact',a, 'is pXR')\n",
    "    elif types[a] == 'pYR':\n",
    "        #append to pyr strain and strainrate\n",
    "        pYR_strain.append(strains[a])\n",
    "        pYR_strainrate.append(strainrates[a])\n",
    "        #print('impact',a, 'is pYR')\n",
    "    elif types[a] == 'pZR':\n",
    "        #append to pzr strain and strainrate\n",
    "        pZR_strain.append(strains[a])\n",
    "        pZR_strainrate.append(strainrates[a])\n",
    "        #print('impact',a, 'is pZR')\n",
    "\n",
    "print(nYR_strain, pYR_strain, pXR_strain, pZR_strain)\n",
    "\n",
    "\n",
    "result_strain = kruskal(nYR_strain, pYR_strain, pXR_strain, pZR_strain)\n",
    "#result_strain = stats.kruskal(nYR_strain, pYR_strain, pXR_strain, pZR_strain)\n",
    "result_strainrate = kruskal(nYR_strainrate, pYR_strainrate, pXR_strainrate, pZR_strainrate)\n",
    "print(result_strain)\n",
    "print(result_strainrate)\n",
    "posthoc_results_strains = posthoc_dunn([nYR_strain, pXR_strain, pYR_strain, pZR_strain], p_adjust='bonferroni')\n",
    "posthoc_results_strainrates = posthoc_dunn([nYR_strainrate, pXR_strainrate, pYR_strainrate, pZR_strainrate], p_adjust='bonferroni')\n",
    "print('strain post hoc test:')\n",
    "print(posthoc_results_strains)\n",
    "print('strain rate post hoc test:')\n",
    "print(posthoc_results_strainrates)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
